import { Hono } from 'hono';
import { cors } from 'hono/cors';
import { logger } from 'hono/logger';
import {
  GeminiClient,
  LocalLLMClient,
  FallbackLLMClient,
  type LLMClient,
  type CacheStorage,
  type CacheMetadata,
  type CacheListItem,
  type UsageLogger,
  type UsageEntry,
  type UsageStats,
  type UsageOperation,
  MnemoConfigSchema,
  calculateCost,
  UrlAdapter,
} from '@mnemo/core';
import { MnemoMCPServer, toolDefinitions } from '@mnemo/mcp-server';

// Local model configuration
const LOCAL_MODEL_URL = 'https://vllm.shiftaltcreate.com';
const LOCAL_MODEL_NAME = 'nemotron-3-nano';
const LOCAL_MODEL_MAX_TOKENS = 131072;

// Env interface is defined in worker-configuration.d.ts (generated by wrangler types)

// Create app with bindings type
const app = new Hono<{ Bindings: Env }>();

// Middleware
app.use('*', cors());
app.use('*', logger());

// ============================================================================
// Rate Limiting with KV Storage
// ============================================================================

interface RateLimitData {
  requests: number;
  tokens: number;
  warningEmailSent: boolean;
  blockedEmailSent: boolean;
}

function getDateKey(): string {
  return new Date().toISOString().split('T')[0]; // YYYY-MM-DD
}

async function getRateLimitData(kv: KVNamespace): Promise<RateLimitData> {
  const key = `ratelimit:daily:${getDateKey()}`;
  const data = await kv.get(key, 'json');
  return (data as RateLimitData) || {
    requests: 0,
    tokens: 0,
    warningEmailSent: false,
    blockedEmailSent: false,
  };
}

async function updateRateLimitData(
  kv: KVNamespace,
  data: RateLimitData
): Promise<void> {
  const key = `ratelimit:daily:${getDateKey()}`;
  // TTL of 48 hours (172800 seconds)
  await kv.put(key, JSON.stringify(data), { expirationTtl: 172800 });
}

// Burst tracking (in-memory, resets on worker restart)
interface BurstEntry {
  count: number;
  windowStart: number;
}
const burstTracker = new Map<string, BurstEntry>();

async function checkBurstLimit(
  ip: string,
  env: Env
): Promise<{ exceeded: boolean; count: number }> {
  const now = Date.now();
  const windowMs = 60000; // 1 minute
  const maxBurst = 50;

  const entry = burstTracker.get(ip);

  if (!entry || now - entry.windowStart > windowMs) {
    burstTracker.set(ip, { count: 1, windowStart: now });
    return { exceeded: false, count: 1 };
  }

  entry.count++;

  if (entry.count > maxBurst) {
    // Send burst alert (async, don't wait)
    sendAlertEmail(
      env,
      'Burst Rate Limit Alert',
      `Unusual burst detected: ${entry.count} requests in 1 minute from IP ${ip}`
    ).catch(console.error);
    return { exceeded: true, count: entry.count };
  }

  return { exceeded: false, count: entry.count };
}

// ============================================================================
// Email Alerts via Resend
// ============================================================================

async function sendAlertEmail(
  env: Env,
  subject: string,
  message: string
): Promise<void> {
  const apiKey = env.RESEND_API_KEY;
  const alertEmail = env.ALERT_EMAIL || 'chris@solamp.io';

  if (!apiKey) {
    console.warn('RESEND_API_KEY not configured, skipping email alert');
    console.log(`Alert: ${subject} - ${message}`);
    return;
  }

  try {
    const response = await fetch('https://api.resend.com/emails', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        from: 'Mnemo Alerts <alerts@solamp.io>',
        to: [alertEmail],
        subject: `[Mnemo] ${subject}`,
        text: `${message}\n\nTimestamp: ${new Date().toISOString()}`,
      }),
    });

    if (!response.ok) {
      const error = await response.text();
      console.error('Failed to send alert email:', error);
    }
  } catch (error) {
    console.error('Error sending alert email:', error);
  }
}

// ============================================================================
// Rate Limiting Middleware
// ============================================================================

const rateLimitMiddleware = () => {
  return async (c: any, next: any) => {
    const env = c.env as Env;
    const kv = env.RATE_LIMIT_KV;
    const ip = c.req.header('CF-Connecting-IP') || 'unknown';

    // Check burst limit first
    const burst = await checkBurstLimit(ip, env);
    if (burst.exceeded) {
      return c.json({
        error: 'Rate limit exceeded',
        message: 'Too many requests in a short period. Please slow down.',
      }, 429);
    }

    // Get daily limits from env
    const dailyRequestLimit = parseInt(env.DAILY_REQUEST_LIMIT || '500', 10);
    const dailyTokenLimit = parseInt(env.DAILY_TOKEN_LIMIT || '2000000', 10);

    // Get current usage
    const data = await getRateLimitData(kv);

    // Check if blocked
    if (data.requests >= dailyRequestLimit) {
      // Send blocked email if not sent yet
      if (!data.blockedEmailSent) {
        data.blockedEmailSent = true;
        await updateRateLimitData(kv, data);
        sendAlertEmail(
          env,
          'Daily Request Limit EXCEEDED',
          `Daily request limit of ${dailyRequestLimit} has been reached.\nTotal requests today: ${data.requests}\nTotal tokens today: ${data.tokens}`
        ).catch(console.error);
      }

      return c.json({
        error: 'Daily limit exceeded',
        message: 'Daily request limit reached. Please try again tomorrow.',
        limit: dailyRequestLimit,
        used: data.requests,
      }, 429);
    }

    // Check warning threshold (80%)
    const warningThreshold = Math.floor(dailyRequestLimit * 0.8);
    if (data.requests >= warningThreshold && !data.warningEmailSent) {
      data.warningEmailSent = true;
      await updateRateLimitData(kv, data);
      sendAlertEmail(
        env,
        'Daily Request Limit Warning (80%)',
        `Approaching daily request limit.\nCurrent requests: ${data.requests} / ${dailyRequestLimit} (${Math.round(data.requests / dailyRequestLimit * 100)}%)\nTotal tokens today: ${data.tokens}`
      ).catch(console.error);
    }

    // Increment request count
    data.requests++;
    await updateRateLimitData(kv, data);

    // Store data in context for token tracking after response
    c.set('rateLimitData', data);

    return await next();
  };
};

// ============================================================================
// Write Protection
// ============================================================================

// Tools that require passphrase (write operations)
const WRITE_TOOLS = ['context_load', 'context_refresh', 'context_evict'];

// Tools that don't require passphrase (read operations)
const READ_TOOLS = ['context_list', 'context_query', 'context_stats'];

/**
 * Check if a tool call requires passphrase and validate it
 * Returns error message if invalid, null if valid
 */
function checkWritePassphrase(
  toolName: string,
  args: Record<string, unknown>,
  env: Env
): string | null {
  // If not a write tool, no passphrase needed
  if (!WRITE_TOOLS.includes(toolName)) {
    return null;
  }

  // If no passphrase configured, allow all writes (backwards compatible)
  const expectedPassphrase = env.WRITE_PASSPHRASE;
  if (!expectedPassphrase) {
    return null;
  }

  // Check passphrase
  const providedPassphrase = args.passphrase as string | undefined;
  if (!providedPassphrase) {
    return 'Write operation requires passphrase';
  }

  if (providedPassphrase !== expectedPassphrase) {
    return 'Invalid passphrase';
  }

  return null;
}

/**
 * Extract tool name and arguments from MCP request
 */
function extractToolInfo(request: any): { toolName: string; args: Record<string, unknown> } | null {
  if (request?.method !== 'tools/call') {
    return null;
  }

  const params = request?.params;
  if (!params?.name || typeof params.name !== 'string') {
    return null;
  }

  return {
    toolName: params.name,
    args: (params.arguments as Record<string, unknown>) || {},
  };
}

// ============================================================================
// Routes
// ============================================================================

// Health check (no rate limit)
app.get('/health', async (c) => {
  // Check if local model is available
  let localModelAvailable = false;
  try {
    const response = await fetch(`${LOCAL_MODEL_URL}/v1/models`, {
      signal: AbortSignal.timeout(5000),
    });
    localModelAvailable = response.ok;
  } catch {
    localModelAvailable = false;
  }

  return c.json({
    status: 'ok',
    service: 'mnemo',
    version: '0.2.0',
    environment: c.env.ENVIRONMENT,
    models: {
      primary: {
        name: LOCAL_MODEL_NAME,
        url: LOCAL_MODEL_URL,
        available: localModelAvailable,
      },
      fallback: {
        name: 'gemini-2.0-flash-001',
        available: true, // Assume Gemini is always available
      },
    },
  });
});

// Service info (no rate limit)
app.get('/', (c) => {
  return c.json({
    name: 'mnemo',
    version: '0.1.0',
    description: 'Extended memory for AI assistants via Gemini context caching',
    endpoints: {
      health: 'GET /health',
      tools: 'GET /tools',
      mcp: 'POST /mcp',
    },
  });
});

// List available tools (no rate limit)
app.get('/tools', (c) => {
  return c.json({ tools: toolDefinitions });
});

// MCP protocol endpoint (rate limited)
app.post('/mcp', rateLimitMiddleware(), async (c) => {
  const server = createMCPServer(c.env);

  try {
    const request = await c.req.json();

    // Check write passphrase for tool calls
    const toolInfo = extractToolInfo(request);
    if (toolInfo) {
      const error = checkWritePassphrase(toolInfo.toolName, toolInfo.args, c.env);
      if (error) {
        return c.json({
          jsonrpc: '2.0',
          id: request.id ?? null,
          result: {
            content: [{ type: 'text', text: `Error: ${error}` }],
            isError: true,
          },
        });
      }
    }

    const response = await server.handleRequest(request);
    return c.json(response);
  } catch (error) {
    return c.json({
      jsonrpc: '2.0',
      id: null,
      error: {
        code: -32700,
        message: 'Parse error',
      },
    }, 400);
  }
});

// Direct tool invocation (rate limited)
app.post('/tools/:toolName', rateLimitMiddleware(), async (c) => {
  const toolName = c.req.param('toolName');
  const server = createMCPServer(c.env);

  try {
    const args = await c.req.json();

    // Check write passphrase
    const passphraseError = checkWritePassphrase(toolName, args, c.env);
    if (passphraseError) {
      return c.json({ error: passphraseError }, 403);
    }

    const response = await server.handleRequest({
      jsonrpc: '2.0',
      id: 1,
      method: 'tools/call',
      params: {
        name: toolName,
        arguments: args,
      },
    });

    // Extract result from MCP response
    if ('result' in response && response.result) {
      return c.json(response.result);
    }
    if ('error' in response && response.error) {
      return c.json({ error: response.error.message }, 400);
    }
    return c.json(response);
  } catch (error) {
    return c.json({ error: 'Invalid request' }, 400);
  }
});

// Usage stats endpoint (for monitoring)
app.get('/stats', async (c) => {
  const kv = c.env.RATE_LIMIT_KV;
  const data = await getRateLimitData(kv);
  const dailyRequestLimit = parseInt(c.env.DAILY_REQUEST_LIMIT || '500', 10);
  const dailyTokenLimit = parseInt(c.env.DAILY_TOKEN_LIMIT || '2000000', 10);

  return c.json({
    date: getDateKey(),
    requests: {
      used: data.requests,
      limit: dailyRequestLimit,
      remaining: Math.max(0, dailyRequestLimit - data.requests),
      percentage: Math.round((data.requests / dailyRequestLimit) * 100),
    },
    tokens: {
      used: data.tokens,
      limit: dailyTokenLimit,
      remaining: Math.max(0, dailyTokenLimit - data.tokens),
      percentage: Math.round((data.tokens / dailyTokenLimit) * 100),
    },
  });
});

// ============================================================================
// Helpers
// ============================================================================

function createMCPServer(env: Env): MnemoMCPServer {
  const config = MnemoConfigSchema.parse({
    geminiApiKey: env.GEMINI_API_KEY,
  });

  // Create Gemini client (for fallback)
  const geminiClient = new GeminiClient(config);

  // Create local model client (Nemotron via vLLM tunnel)
  const localClient = new LocalLLMClient({
    baseUrl: LOCAL_MODEL_URL,
    model: LOCAL_MODEL_NAME,
    maxContextTokens: LOCAL_MODEL_MAX_TOKENS,
    timeout: 120000,
  });

  // Create fallback client: Nemotron primary, Gemini fallback
  const llmClient = new FallbackLLMClient({
    primary: localClient,
    fallback: geminiClient,
    autoFallbackForLargeContext: true,
    onFallbackNeeded: async (event) => {
      console.log(`Fallback to Gemini: ${event.reason} - ${event.details ?? 'N/A'}`);
      return true; // Auto-approve fallback in CF worker
    },
  });

  const storage = new D1CacheStorage(env.DB);
  const usageLogger = new D1UsageLogger(env.DB);
  // Workers have a 50 subrequest limit, use 40 to leave headroom
  const urlAdapter = new UrlAdapter({ maxSubrequests: 40 });

  return new MnemoMCPServer({
    geminiClient: llmClient,
    storage,
    usageLogger,
    urlAdapter,
  });
}

// ============================================================================
// D1 Storage Implementation
// ============================================================================

class D1CacheStorage implements CacheStorage {
  constructor(private db: D1Database) {}

  async save(metadata: CacheMetadata): Promise<void> {
    await this.db
      .prepare(
        `INSERT INTO caches (id, alias, gemini_cache_name, source, token_count, model, expires_at)
         VALUES (?, ?, ?, ?, ?, ?, ?)
         ON CONFLICT(alias) DO UPDATE SET
           gemini_cache_name = excluded.gemini_cache_name,
           source = excluded.source,
           token_count = excluded.token_count,
           model = excluded.model,
           expires_at = excluded.expires_at`
      )
      .bind(
        crypto.randomUUID(),
        metadata.alias,
        metadata.name,
        metadata.source,
        metadata.tokenCount,
        metadata.model ?? null,
        metadata.expiresAt.toISOString()
      )
      .run();
  }

  async getByAlias(alias: string): Promise<CacheMetadata | null> {
    const result = await this.db
      .prepare('SELECT * FROM caches WHERE alias = ?')
      .bind(alias)
      .first<{
        id: string;
        alias: string;
        gemini_cache_name: string;
        source: string;
        token_count: number;
        model: string | null;
        created_at: string;
        expires_at: string;
      }>();

    if (!result) return null;

    return {
      name: result.gemini_cache_name,
      alias: result.alias,
      tokenCount: result.token_count,
      createdAt: new Date(result.created_at),
      expiresAt: new Date(result.expires_at),
      source: result.source,
      model: result.model ?? undefined,
    };
  }

  async getByName(name: string): Promise<CacheMetadata | null> {
    const result = await this.db
      .prepare('SELECT * FROM caches WHERE gemini_cache_name = ?')
      .bind(name)
      .first<{
        id: string;
        alias: string;
        gemini_cache_name: string;
        source: string;
        token_count: number;
        model: string | null;
        created_at: string;
        expires_at: string;
      }>();

    if (!result) return null;

    return {
      name: result.gemini_cache_name,
      alias: result.alias,
      tokenCount: result.token_count,
      createdAt: new Date(result.created_at),
      expiresAt: new Date(result.expires_at),
      source: result.source,
      model: result.model ?? undefined,
    };
  }

  async list(): Promise<CacheListItem[]> {
    const results = await this.db
      .prepare('SELECT alias, token_count, expires_at, source FROM caches ORDER BY created_at DESC')
      .all<{
        alias: string;
        token_count: number;
        expires_at: string;
        source: string;
      }>();

    return (results.results ?? []).map((row) => ({
      alias: row.alias,
      tokenCount: row.token_count,
      expiresAt: new Date(row.expires_at),
      source: row.source,
    }));
  }

  async deleteByAlias(alias: string): Promise<boolean> {
    const result = await this.db
      .prepare('DELETE FROM caches WHERE alias = ?')
      .bind(alias)
      .run();
    return (result.meta?.changes ?? 0) > 0;
  }

  async update(alias: string, updates: Partial<CacheMetadata>): Promise<void> {
    const sets: string[] = [];
    const values: unknown[] = [];

    if (updates.expiresAt) {
      sets.push('expires_at = ?');
      values.push(updates.expiresAt.toISOString());
    }
    if (updates.tokenCount !== undefined) {
      sets.push('token_count = ?');
      values.push(updates.tokenCount);
    }

    if (sets.length === 0) return;

    values.push(alias);
    await this.db
      .prepare(`UPDATE caches SET ${sets.join(', ')} WHERE alias = ?`)
      .bind(...values)
      .run();
  }
}

// ============================================================================
// D1 Usage Logger Implementation
// ============================================================================

class D1UsageLogger implements UsageLogger {
  constructor(private db: D1Database) {}

  async log(entry: Omit<UsageEntry, 'createdAt'>): Promise<void> {
    await this.db
      .prepare(
        `INSERT INTO usage_logs (cache_id, operation, tokens_used, cached_tokens_used)
         VALUES (?, ?, ?, ?)`
      )
      .bind(entry.cacheId, entry.operation, entry.tokensUsed, entry.cachedTokensUsed)
      .run();
  }

  async getStats(cacheId?: string): Promise<UsageStats> {
    const whereClause = cacheId ? 'WHERE cache_id = ?' : '';

    // Get totals
    const totalsStmt = this.db.prepare(
      `SELECT
        COUNT(*) as total_ops,
        COALESCE(SUM(tokens_used), 0) as total_tokens,
        COALESCE(SUM(cached_tokens_used), 0) as total_cached
       FROM usage_logs ${whereClause}`
    );
    const totals = cacheId
      ? await totalsStmt.bind(cacheId).first<{ total_ops: number; total_tokens: number; total_cached: number }>()
      : await totalsStmt.first<{ total_ops: number; total_tokens: number; total_cached: number }>();

    // Get breakdown by operation
    const byOpStmt = this.db.prepare(
      `SELECT
        operation,
        COUNT(*) as count,
        COALESCE(SUM(tokens_used), 0) as tokens_used,
        COALESCE(SUM(cached_tokens_used), 0) as cached_tokens_used
       FROM usage_logs ${whereClause}
       GROUP BY operation`
    );
    const byOpResults = cacheId
      ? await byOpStmt.bind(cacheId).all<{
          operation: string;
          count: number;
          tokens_used: number;
          cached_tokens_used: number;
        }>()
      : await byOpStmt.all<{
          operation: string;
          count: number;
          tokens_used: number;
          cached_tokens_used: number;
        }>();

    const byOperation: Record<UsageOperation, { count: number; tokensUsed: number; cachedTokensUsed: number }> = {
      load: { count: 0, tokensUsed: 0, cachedTokensUsed: 0 },
      query: { count: 0, tokensUsed: 0, cachedTokensUsed: 0 },
      evict: { count: 0, tokensUsed: 0, cachedTokensUsed: 0 },
      refresh: { count: 0, tokensUsed: 0, cachedTokensUsed: 0 },
    };

    for (const row of byOpResults.results ?? []) {
      const op = row.operation as UsageOperation;
      if (op in byOperation) {
        byOperation[op] = {
          count: row.count,
          tokensUsed: row.tokens_used,
          cachedTokensUsed: row.cached_tokens_used,
        };
      }
    }

    const totalTokens = totals?.total_tokens ?? 0;
    const totalCached = totals?.total_cached ?? 0;

    return {
      totalOperations: totals?.total_ops ?? 0,
      totalTokensUsed: totalTokens,
      totalCachedTokensUsed: totalCached,
      estimatedCost: calculateCost(totalTokens, totalCached),
      byOperation,
    };
  }

  async getRecent(limit = 100): Promise<UsageEntry[]> {
    const results = await this.db
      .prepare(
        `SELECT cache_id, operation, tokens_used, cached_tokens_used, created_at
         FROM usage_logs
         ORDER BY created_at DESC
         LIMIT ?`
      )
      .bind(limit)
      .all<{
        cache_id: string;
        operation: string;
        tokens_used: number;
        cached_tokens_used: number;
        created_at: string;
      }>();

    return (results.results ?? []).map((row) => ({
      cacheId: row.cache_id,
      operation: row.operation as UsageOperation,
      tokensUsed: row.tokens_used,
      cachedTokensUsed: row.cached_tokens_used,
      createdAt: new Date(row.created_at),
    }));
  }
}

export default app;
